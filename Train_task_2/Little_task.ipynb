{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Это финальное задание по курсу «Обучение на размеченных данных».\n",
    "\n",
    "В нем вы сравните логистическую регрессию и случайный лес на разных наборах признаков. В качестве данных будет использован Adult Data Set из репозитория UCI. В нем нужно предсказать, получает ли человек больше 50 000$ в год, или нет, по ряду признаков, таких как пол, образование, раса и др. Подробное описание можно найти по ссылке: https://archive.ics.uci.edu/ml/datasets/Adult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе задания будем использовать __train_data.csv__ для обучения моделей, на нем же и будем производить кросс-валидацию. В качестве отложенной выборки будем использовать __test_data.csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "                \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "                \"hours-per-week\", \"native-country\", \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\", sep=\", \", header=None, engine=\"python\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_data.csv\", sep=\", \", header=None, engine=\"python\", names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Пропущенные значения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке порядка 7% строк имеют пропущенные значения (вместо значения поля указан вопросительный знак __'?'__). В каких признаках в обучающей и тестовой выборке имеются пропущенные значения? Так как они все пропущены в категориальных признаках, то можно пока их ни на что не заменять, а просто считать еще одной категорией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переименуем колонки для удобства доступа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.rename(columns={'education-num': 'education_num', \"marital-status\": \"marital_status\", \n",
    "                                                                \"capital-gain\": \"capital_gain\" , \"capital-loss\": \"capital_loss\", \n",
    "                                                                \"hours-per-week\": \"hours_per_week\",\n",
    "                                                                \"native-country\": \"native_country\"\n",
    "                                                               })\n",
    "X_test = test.rename(columns={'education-num': 'education_num', \"marital-status\": \"marital_status\", \n",
    "                                                                \"capital-gain\": \"capital_gain\" , \"capital-loss\": \"capital_loss\", \n",
    "                                                                \"hours-per-week\": \"hours_per_week\",\n",
    "                                                                \"native-country\": \"native_country\"\n",
    "                                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape == train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <=50K\n",
       "1    <=50K\n",
       "2    <=50K\n",
       "3    <=50K\n",
       "4    <=50K\n",
       "5    <=50K\n",
       "6    <=50K\n",
       "7     >50K\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = X_train['class']\n",
    "y_test = X_test['class']\n",
    "y_train.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['class'], axis=1)\n",
    "X_test = X_test.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education_num        0\n",
       "marital_status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital_gain         0\n",
       "capital_loss         0\n",
       "hours_per_week       0\n",
       "native_country     583\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train == '?'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "workclass         963\n",
       "fnlwgt              0\n",
       "education           0\n",
       "education_num       0\n",
       "marital_status      0\n",
       "occupation        966\n",
       "relationship        0\n",
       "race                0\n",
       "sex                 0\n",
       "capital_gain        0\n",
       "capital_loss        0\n",
       "hours_per_week      0\n",
       "native_country    274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test == '?'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что значения пропущены в признаках с именами: \"occupation\", \"workclass\", \"native_country\". При кодировании будем считать \"?\" еще одной категорией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучение на вещественных признаках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе обучите модели только на вещественных признаках (\"continuous\" в описании данных). Обучите логистическую регрессию (linear_model.LogisticRegression) и случайный лес (ensemble.RandomForestClassifier) из sklearn. В первом случае подберите оптимальные параметры $penalty$ и $C$ на отрезке $[10^{-6}, 10^{6}]$ (по степеням $10$ с шагом $1$, начиная с $-6$), а во втором при фиксированном числе деревьев в 50 подберите $max\\_depth$ и $min\\_samples\\_split$ из отрезка $[2, 14]$ с шагом в 2 и множества $\\{1, 2, 4, 8\\}$ соответственно. За целевую метрику качества возьмите AUC-ROC. В качестве схемы валидации используйте стратифицированную кросс-валидацию по 5-ти фолдам. Какие параметры оказались оптимальными?\n",
    "\n",
    "Учтите, что целевая переменная в датасете является строкой. Поэтому для начала ее нужно перевести в бинарную величину. Также не забудьте отмасштабировать данные с помощью StandartScaler'а из модуля preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss',\n",
       "       'hours_per_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оставляем вещественные признаки\n",
    "X_train_continuous = X_train.drop(['workclass', 'education', 'marital_status', 'occupation', 'relationship',\n",
    "                       'race', 'sex', 'native_country'], axis=1)\n",
    "X_train_continuous.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss',\n",
       "       'hours_per_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_continuous = X_test.drop(['workclass', 'education', 'marital_status', 'occupation', 'relationship',\n",
    "                       'race', 'sex', 'native_country'], axis=1)\n",
    "X_test_continuous.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# масштабируем\n",
    "scaler_train = StandardScaler()\n",
    "X_train_continuous = scaler_train.fit_transform(X_train_continuous)\n",
    "\n",
    "scaler_test = StandardScaler()\n",
    "X_test_continuous = scaler_test.fit_transform(X_test_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем ответы в два численных класса\n",
    "y_train[y_train == '<=50K'] = 1\n",
    "y_train[y_train == '>50K'] = 0\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "y_test[y_test == '<=50K'] = 1\n",
    "y_test[y_test == '>50K'] = 0\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем модели\n",
    "classifier_log = LogisticRegression(random_state=0, max_iter=10000)\n",
    "classifier_randf = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "# задаем параметры для сетки\n",
    "parameters_grid_log = {\n",
    "    'C': [10**i for i in range(-6, 7)],\n",
    "}\n",
    "\n",
    "parameters_grid_randf = {\n",
    "    'max_depth': range(2, 15, 2),\n",
    "    'min_samples_split': [1., 2, 4, 8],\n",
    "}\n",
    "\n",
    "grid_cv_log = GridSearchCV(classifier_log, parameters_grid_log, scoring = 'roc_auc', cv=5)\n",
    "grid_cv_randf = GridSearchCV(classifier_randf, parameters_grid_randf, scoring = 'roc_auc', cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_log.fit(X_train_continuous, y_train)\n",
    "grid_cv_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8316100306392272\n",
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_log.best_score_)\n",
    "print(grid_cv_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_randf.fit(X_train_continuous, y_train)\n",
    "grid_cv_randf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634784804180331\n",
      "{'max_depth': 12, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_randf.best_score_)\n",
    "print(grid_cv_randf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте accuracy, precision, recall, f1-score и AUC-ROC на отложенной выборке для оптимальных алгоритмов. Какие они получились? Какой алгоритм лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log = grid_cv_log.best_estimator_.predict(X_test_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_randf = grid_cv_randf.best_estimator_.predict(X_test_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(predicted, target):\n",
    "    print('AUC-ROC:', roc_auc_score(predicted, y_test))\n",
    "    print('Accuracy', accuracy_score(y_test, predicted))\n",
    "    print('F1-score:', f1_score(y_test, predicted))\n",
    "    print('Recall:', recall_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.7591389196647307\n",
      "Accuracy 0.8127264910017812\n",
      "F1-score: 0.8852853756725234\n",
      "Recall: 0.9461198230800161\n"
     ]
    }
   ],
   "source": [
    "print_score(predicted_log, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.8042857325334096\n",
      "Accuracy 0.8347767336158712\n",
      "F1-score: 0.8985441653466094\n",
      "Recall: 0.9579412947326096\n"
     ]
    }
   ],
   "source": [
    "print_score(predicted_randf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, лес лучше справился с задачей по всем метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Категориальные признаки как есть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь к вещественным добавьте категориальные признаки, заменив их на числа с помощью LabelEncoder из модуля preprocessing. Переподберите параметры для логистической регрессии и случайного леса аналогично прошлому пункту. Как изменилось качество моделей на тестовой выборке? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# т.к. LabelEncoder предназначен для одномерных массивов, воспользуемся OrdinalEncoder, хотя возможно и через цикл с помощью LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "X_train_cat = X_train.drop([\"age\", \"fnlwgt\", \"education_num\",\n",
    "                \"capital_gain\", \"capital_loss\", \"hours_per_week\"], axis=1)\n",
    "X_test_cat = X_test.drop([\"age\", \"fnlwgt\", \"education_num\",\n",
    "                \"capital_gain\", \"capital_loss\", \"hours_per_week\"], axis=1)\n",
    "\n",
    "encoder_train = OrdinalEncoder()\n",
    "X_train_cat_enc = encoder_train.fit_transform(X_train_cat)\n",
    "\n",
    "encoder_test = OrdinalEncoder()\n",
    "X_test_cat_enc = encoder_test.fit_transform(X_test_cat)\n",
    "\n",
    "X_train = np.hstack((X_train_cat_enc, X_train_continuous))\n",
    "X_test = np.hstack((X_test_cat_enc, X_test_continuous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0] == train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0] == test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_log_cat_enc = GridSearchCV(classifier_log, parameters_grid_log, scoring='roc_auc', cv=5)\n",
    "grid_cv_randf_cat_enc = GridSearchCV(classifier_randf, parameters_grid_randf, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_log_cat_enc.fit(X_train, y_train)\n",
    "grid_cv_log_cat_enc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_randf_cat_enc.fit(X_train, y_train)\n",
    "grid_cv_randf_cat_enc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538968851535212\n",
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_log_cat_enc.best_score_)\n",
    "print(grid_cv_log_cat_enc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_randf_cat_enc.fit(X_train, y_train)\n",
    "grid_cv_randf_cat_enc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166620837732443\n",
      "{'max_depth': 12, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_randf_cat_enc.best_score_)\n",
    "print(grid_cv_randf_cat_enc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_cat_enc = grid_cv_log_cat_enc.best_estimator_.predict(X_test)\n",
    "predicted_randf_cat_enc = grid_cv_randf_cat_enc.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.774595203055598\n",
      "Accuracy 0.8245193784165592\n",
      "F1-score: 0.8913068289899182\n",
      "Recall: 0.9420184961801367\n"
     ]
    }
   ],
   "source": [
    "print_score(predicted_log_cat_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.8295704491950132\n",
      "Accuracy 0.8586081935999017\n",
      "F1-score: 0.9115227919132909\n",
      "Recall: 0.9535987133092079\n"
     ]
    }
   ],
   "source": [
    "print_score(predicted_randf_cat_enc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Бинарное кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь замените категориальные признаки из прошлого пункта на бинарно закодированные. Опять переподберите параметры для моделей и проверьте качество на тестовой выборке. Как изменилось качество относительно предыдущего пункта? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "binarizer_train = LabelBinarizer()\n",
    "for col in X_train_cat.columns:\n",
    "    X_train_cat[col] = binarizer_train.fit_transform(X_train_cat[col])\n",
    "\n",
    "binarizer_test = LabelBinarizer()\n",
    "for col in X_test_cat.columns:\n",
    "    X_test_cat[col] = binarizer_test.fit_transform(X_test_cat[col])\n",
    "\n",
    "X_train2 = np.hstack((X_train_cat, X_train_continuous))\n",
    "X_test2 = np.hstack((X_test_cat, X_test_continuous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_log_cat_binarize = GridSearchCV(classifier_log, parameters_grid_log, scoring = 'roc_auc', cv=5)\n",
    "grid_cv_randf_cat_binarize = GridSearchCV(classifier_randf, parameters_grid_randf, scoring = 'roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_log_cat_binarize.fit(X_train2, y_train)\n",
    "grid_cv_log_cat_binarize.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8769851259244339\n",
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_log_cat_binarize.best_score_)\n",
    "print(grid_cv_log_cat_binarize.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=14, min_samples_split=4, n_estimators=50,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_randf_cat_binarize.fit(X_train2, y_train)\n",
    "grid_cv_randf_cat_binarize.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8993103325921382\n",
      "{'max_depth': 14, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_randf_cat_binarize.best_score_)\n",
    "print(grid_cv_randf_cat_binarize.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_cat_binarize = grid_cv_log_cat_binarize.best_estimator_.predict(X_test2)\n",
    "predicted_randf_cat_binarize = grid_cv_randf_cat_binarize.best_estimator_.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First model \n",
      "AUC-ROC 1: 0.7591389196647307\n",
      "Accuracy 1 0.8127264910017812\n",
      "F1-score 1: 0.8852853756725234\n",
      "Recall 1: 0.9461198230800161\n",
      " Second model \n",
      "AUC-ROC 3: 0.774595203055598\n",
      "Accuracy 3 0.8245193784165592\n",
      "F1-score 3: 0.8913068289899182\n",
      "Recall3: 0.9420184961801367\n",
      " Third model \n",
      "AUC-ROC 4: 0.7893440624965217\n",
      "Accuracy 4: 0.8376021128923284\n",
      "F1-score 4: 0.898048893344644\n",
      "Recall 4: 0.9364696421391234\n"
     ]
    }
   ],
   "source": [
    "print(' First model', '\\nAUC-ROC 1:', roc_auc_score(predicted_log, y_test))\n",
    "print('Accuracy 1', accuracy_score(y_test, predicted_log))\n",
    "print('F1-score 1:', f1_score(y_test, predicted_log))\n",
    "print('Recall 1:', recall_score(y_test, predicted_log))\n",
    "\n",
    "print(' Second model', '\\nAUC-ROC 3:', roc_auc_score(predicted_log_cat_enc, y_test))\n",
    "print('Accuracy 3', accuracy_score(y_test, predicted_log_cat_enc))\n",
    "print('F1-score 3:', f1_score(y_test, predicted_log_cat_enc))\n",
    "print('Recall3:', recall_score(y_test, predicted_log_cat_enc))\n",
    "\n",
    "print(' Third model', '\\nAUC-ROC 4:', roc_auc_score(predicted_log_cat_binarize, y_test))\n",
    "print('Accuracy 4:', accuracy_score(y_test, predicted_log_cat_binarize))\n",
    "print('F1-score 4:', f1_score(y_test, predicted_log_cat_binarize))\n",
    "print('Recall 4:', recall_score(y_test, predicted_log_cat_binarize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First model \n",
      "AUC-ROC 1: 0.8042857325334096\n",
      "Accuracy 1: 0.8347767336158712\n",
      "F1-score 1: 0.8985441653466094\n",
      "Recall 1: 0.9579412947326096\n",
      " Second model \n",
      "AUC-RO 3: 0.8295704491950132\n",
      "Accuracy 3: 0.8586081935999017\n",
      "F1-score 3: 0.9115227919132909\n",
      "Recall 3: 0.9535987133092079\n",
      " Third model \n",
      "AUC-ROC 4: 0.8258405290462604\n",
      "Accuracy 4: 0.8515447454087587\n",
      "F1-score 4: 0.9078992493236292\n",
      "Recall 4: 0.958021712907117\n"
     ]
    }
   ],
   "source": [
    "print(' First model', '\\nAUC-ROC 1:', roc_auc_score(predicted_randf, y_test))\n",
    "print('Accuracy 1:', accuracy_score(y_test, predicted_randf))\n",
    "print('F1-score 1:', f1_score(y_test, predicted_randf))\n",
    "print('Recall 1:', recall_score(y_test, predicted_randf))\n",
    "\n",
    "print(' Second model', '\\nAUC-RO 3:', roc_auc_score(predicted_randf_cat_enc, y_test))\n",
    "print('Accuracy 3:', accuracy_score(y_test, predicted_randf_cat_enc))\n",
    "print('F1-score 3:', f1_score(y_test, predicted_randf_cat_enc))\n",
    "print('Recall 3:', recall_score(y_test, predicted_randf_cat_enc))\n",
    "\n",
    "print(' Third model', '\\nAUC-ROC 4:', roc_auc_score(predicted_randf_cat_binarize, y_test))\n",
    "print('Accuracy 4:', accuracy_score(y_test, predicted_randf_cat_binarize))\n",
    "print('F1-score 4:', f1_score(y_test, predicted_randf_cat_binarize))\n",
    "print('Recall 4:', recall_score(y_test, predicted_randf_cat_binarize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
